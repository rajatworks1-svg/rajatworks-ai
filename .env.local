# ==============================================================================
# MIRA AI - LOCALAI CONFIGURATION (Phase 1)
# ==============================================================================

# 1. LLM Model Settings (Self-Hosted via LocalAI)
# ------------------------------------------------------------------------------
# We are setting the base URL to your local machine (127.0.0.1) where LocalAI will run.
# Change this ONLY when you move the server to a cloud provider (e.g., RunPod, AWS).

LOCALAI_BASE_URL="http://127.0.0.1:8080/v1" 
LOCALAI_MODEL_NAME="Llama-3-8B-GGUF"


# 2. DELETE OLD KEYS (OpenAI/Tavily/Others)
# ------------------------------------------------------------------------------
# We must remove all reliance on paid APIs. The lines below are commented out.
# OPENAI_API_KEY=[YOUR_OPENAI_API_KEY]
# TAVILY_API_KEY=[YOUR_TAVILY_API_KEY] 
# FIRECRAWL_API_KEY=[YOUR_FIRECRAWL_API_KEY]
# GOOGLE_GENERATIVE_AI_API_KEY=[YOUR_GOOGLE_GENERATIVE_AI_API_KEY]
# ANTHROPIC_API_KEY=[YOUR_ANTHROPIC_API_KEY]
# GROQ_API_KEY=[YOUR_GROQ_API_KEY]
# SERPER_API_KEY=[YOUR_SERPER_API_KEY]
# JINA_API_KEY=[YOUR_JINA_API_KEY]


# 3. SUPABASE CONFIGURATION (KEEP THESE)
# ------------------------------------------------------------------------------
# You MUST uncomment and update these lines with your actual Supabase URL and Key
# NEXT_PUBLIC_SUPABASE_URL=[YOUR_NEXT_PUBLIC_SUPABASE_URL]
# NEXT_PUBLIC_SUPABASE_ANON_KEY=[YOUR_NEXT_PUBLIC_SUPABASE_ANON_KEY]


# 4. ADDITIONAL FEATURES (Keep these commented or uncomment based on your existing setup)
# ------------------------------------------------------------------------------
# ENABLE_SAVE_CHAT_HISTORY=true
# NEXT_PUBLIC_ENABLE_SHARE=true
# BASE_URL=http://localhost:3000
